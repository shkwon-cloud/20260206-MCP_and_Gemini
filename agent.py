# agent.py
import asyncio
import os
import logging
import json
from dotenv import load_dotenv
from openai import AsyncOpenAI
from fastmcp import Client

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# 2. ë¡œì»¬ì— ë–  ìˆëŠ” MCP ì„œë²„(Fashion Server)ì— ì—°ê²°
MCP_SERVER_URL = "http://localhost:8002/sse"
mcp_client = Client(MCP_SERVER_URL)

# 3. OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_INSTRUCTION = """
ë‹¹ì‹ ì€ íŒ¨ì…˜ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ë°˜ë“œì‹œ ì œê³µëœ ë„êµ¬(tools)ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ê³ , ë°˜ë“œì‹œ ë„êµ¬ë¥¼ í˜¸ì¶œí•´ì„œ ì •ë³´ë¥¼ ì–»ì€ í›„ ë‹µë³€í•˜ì„¸ìš”.
"""

async def main():
    logger.info("=" * 60)
    logger.info("ğŸ¤– OpenAI Agent ì‹œì‘")
    logger.info(f"ğŸ”— MCP ì„œë²„ URL: {MCP_SERVER_URL}")
    logger.info("=" * 60)

    # MCP í´ë¼ì´ì–¸íŠ¸ ì„¸ì…˜ ì‹œì‘
    logger.info("ğŸ“¡ MCP ì„œë²„ì— ì—°ê²° ì¤‘...")
    async with mcp_client:
        logger.info("âœ… MCP ì„œë²„ ì—°ê²° ì„±ê³µ!")

        # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ í™•ì¸
        tools_list = await mcp_client.list_tools()
        logger.info(f"ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ({len(tools_list)}ê°œ):")
        
        # OpenAI í˜•ì‹ìœ¼ë¡œ ë„êµ¬ ë³€í™˜
        openai_tools = []
        for tool in tools_list:
            logger.info(f"   - {tool.name}: {tool.description[:50]}...")
            # MCP ë„êµ¬ì˜ inputSchemaë¥¼ OpenAIì˜ parametersë¡œ ë§µí•‘
            # inputSchemaê°€ ì§ì ‘ ë„êµ¬ ê°ì²´ì— ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë”•ì…”ë„ˆë¦¬ ë³€í™˜ ì‹œë„
            openai_tools.append({
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": getattr(tool, 'inputSchema', {}),
                }
            })

        # ì§ˆë¬¸ ì •ì˜
        user_query = "ideabongì—ê²Œ ì˜¤ëŠ˜ ë‚ ì”¨ì— ë§ì¶°ì„œ ì˜·ì„ ì¶”ì²œí•´ì¤˜. ì§€ë‚œì£¼ í™”ìš”ì¼ì— ì…ì€ ê±°ë‘ ì•ˆ ê²¹ì¹˜ê²Œ í•´ì¤˜."

        logger.info("-" * 60)
        logger.info(f"ğŸ™‹ ì‚¬ìš©ì ì§ˆë¬¸: {user_query}")
        logger.info("-" * 60)

        # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        messages = [
            {"role": "system", "content": SYSTEM_INSTRUCTION},
            {"role": "user", "content": user_query}
        ]

        logger.info("ğŸ§  OpenAI API í˜¸ì¶œ ì¤‘... (ë„êµ¬ í™œìš©)")

        # 1. ì´ˆê¸° í˜¸ì¶œ
        response = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            tools=openai_tools,
            temperature=0,
        )

        # 2. ë„êµ¬ í˜¸ì¶œ ë£¨í”„
        while response.choices[0].message.tool_calls:
            assistant_message = response.choices[0].message
            messages.append(assistant_message)
            
            tool_calls = assistant_message.tool_calls
            for tool_call in tool_calls:
                tool_name = tool_call.function.name
                tool_args = json.loads(tool_call.function.arguments)
                
                logger.info(f"ğŸ› ï¸ MCP ë„êµ¬ í˜¸ì¶œ: {tool_name}({tool_args})")
                
                try:
                    # mcp_client.call_toolì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë„êµ¬ ì‹¤í–‰
                    call_result = await mcp_client.call_tool(tool_name, tool_args)
                    
                    # ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    tool_output = ""
                    if hasattr(call_result, 'content'):
                        # typical MCP content is a list of TextContent/ImageContent
                        tool_output = "\n".join([
                            c.text for c in call_result.content 
                            if hasattr(c, 'text')
                        ])
                    else:
                        tool_output = str(call_result)
                        
                except Exception as e:
                    tool_output = f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                    logger.error(f"   âŒ ë„êµ¬ í˜¸ì¶œ ì‹¤íŒ¨: {tool_output}")

                logger.info(f"   âœ… ê²°ê³¼: {tool_output[:100]}...")
                
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": tool_name,
                    "content": tool_output,
                })

            # ë„êµ¬ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì—¬ ë‹¤ì‹œ í˜¸ì¶œ
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                tools=openai_tools,
                temperature=0,
            )

        # ìµœì¢… ì‘ë‹µ ì¶”ì¶œ
        final_response = response.choices[0].message.content

        # ì‘ë‹µ ë©”íƒ€ë°ì´í„° ì¶œë ¥
        logger.info("-" * 60)
        logger.info("ğŸ“Š ì‘ë‹µ ë©”íƒ€ë°ì´í„°:")
        logger.info(f"   - model: {response.model}")
        if hasattr(response, 'usage'):
            logger.info(f"   - ì…ë ¥ í† í°: {response.usage.prompt_tokens}")
            logger.info(f"   - ì¶œë ¥ í† í°: {response.usage.completion_tokens}")

        logger.info("-" * 60)
        logger.info("ğŸ¤– OpenAI ì‘ë‹µ:")
        logger.info("-" * 60)
        print(f"\n{final_response}\n")
        logger.info("=" * 60)
        logger.info("âœ… Agent ì‘ì—… ì™„ë£Œ!")
        logger.info("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())