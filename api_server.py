# api_server.py
import os
import logging
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from openai import AsyncOpenAI
from fastmcp import Client
import uvicorn
import json

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# MCP ì„œë²„ ëª©ë¡ (ì—¬ëŸ¬ ì„œë²„ ì§€ì›)
MCP_SERVERS = {
    "fashion": "http://localhost:8002/sse",   # Fashion Server
    "weather": "http://localhost:8003/sse",   # Korea Weather Server
}

# 2. FastAPI ì•± ìƒì„±
app = FastAPI(title="AI Stylist API")

# CORS ì„¤ì • (React ì—°ë™ í•„ìˆ˜)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_INSTRUCTION = """
ë‹¹ì‹ ì€ íŒ¨ì…˜ & ë‚ ì”¨ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ë°˜ë“œì‹œ ì œê³µëœ ë„êµ¬(tools)ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
- íŒ¨ì…˜/ìŠ¤íƒ€ì¼ ê´€ë ¨ ì§ˆë¬¸: get_member_profile, get_ootd_history ë„êµ¬ ì‚¬ìš©
- ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸: get_korea_weather, get_weather_forecast, get_current_weather ë„êµ¬ ì‚¬ìš©
ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ê³ , ë°˜ë“œì‹œ ë„êµ¬ë¥¼ í˜¸ì¶œí•´ì„œ ì •ë³´ë¥¼ ì–»ì€ í›„ ë‹µë³€í•˜ì„¸ìš”.
"""

# 3. ìš”ì²­ ë°ì´í„° êµ¬ì¡° ì •ì˜
class ChatRequest(BaseModel):
    query: str  # ì˜ˆ: "ideabong ì˜¤ëŠ˜ ë­ ì…ì–´?" ë˜ëŠ” "ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜"

# 4. OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì „ì—­ìœ¼ë¡œ í•œ ë²ˆë§Œ)
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# MCP ë„êµ¬ë¥¼ OpenAI í•¨ìˆ˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
def convert_mcp_tools_to_openai(mcp_tools):
    """MCP ë„êµ¬ ëª©ë¡ì„ OpenAI function calling í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    openai_tools = []
    for tool in mcp_tools:
        openai_tool = {
            "type": "function",
            "function": {
                "name": tool.name,
                "description": tool.description or "",
                "parameters": tool.inputSchema if hasattr(tool, 'inputSchema') and tool.inputSchema else {"type": "object", "properties": {}}
            }
        }
        openai_tools.append(openai_tool)
    return openai_tools

# ë„êµ¬ ì´ë¦„ìœ¼ë¡œ í•´ë‹¹ MCP í´ë¼ì´ì–¸íŠ¸ ì°¾ê¸°
def find_mcp_client_for_tool(tool_name: str, tool_to_client_map: dict):
    """ë„êµ¬ ì´ë¦„ìœ¼ë¡œ í•´ë‹¹ MCP í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    return tool_to_client_map.get(tool_name)

# 5. ì„œë²„ ì‹œì‘ ì‹œ ë„êµ¬ ëª©ë¡ ì¶œë ¥
@app.on_event("startup")
async def startup_event():
    logger.info("ğŸ“¡ MCP ì„œë²„ë“¤ì— ì—°ê²°í•˜ì—¬ ë„êµ¬ ëª©ë¡ í™•ì¸ ì¤‘...")
    
    for server_name, server_url in MCP_SERVERS.items():
        try:
            mcp_client = Client(server_url)
            async with mcp_client:
                tools_list = await mcp_client.list_tools()
                logger.info(f"ğŸ“¦ [{server_name.upper()}] ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ({len(tools_list)}ê°œ):")
                for tool in tools_list:
                    logger.info(f"   ğŸ“Œ {tool.name}")
                    logger.info(f"      ì„¤ëª…: {tool.description}")
                    if hasattr(tool, 'inputSchema') and tool.inputSchema:
                        params = tool.inputSchema.get('properties', {})
                        if params:
                            logger.info(f"      íŒŒë¼ë¯¸í„°: {list(params.keys())}")
        except Exception as e:
            logger.warning(f"âš ï¸ [{server_name.upper()}] MCP ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")

# 6. API ì—”ë“œí¬ì¸íŠ¸ ìƒì„±
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    """
    Reactì—ì„œ ì§ˆë¬¸ì„ ë°›ì•„ OpenAI Agentë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì—¬ëŸ¬ MCP ì„œë²„ì˜ ë„êµ¬ë¥¼ í†µí•©í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    logger.info(f"ğŸ“¨ ìš”ì²­ ë°›ìŒ: {request.query}")

    try:
        # (1) ëª¨ë“  MCP í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ë° ë„êµ¬ ìˆ˜ì§‘
        all_openai_tools = []
        tool_to_server = {}  # ë„êµ¬ ì´ë¦„ -> ì„œë²„ URL ë§¤í•‘
        mcp_clients = {}     # ì„œë²„ URL -> Client ê°ì²´
        
        for server_name, server_url in MCP_SERVERS.items():
            try:
                mcp_client = Client(server_url)
                await mcp_client.__aenter__()  # ì—°ê²° ì‹œì‘
                mcp_clients[server_url] = mcp_client
                
                tools_list = await mcp_client.list_tools()
                openai_tools = convert_mcp_tools_to_openai(tools_list)
                
                for tool in openai_tools:
                    tool_name = tool['function']['name']
                    tool_to_server[tool_name] = server_url
                    all_openai_tools.append(tool)
                
                logger.info(f"âœ… [{server_name.upper()}] ì—°ê²° ì„±ê³µ - {len(tools_list)}ê°œ ë„êµ¬ ë¡œë“œ")
                
            except Exception as e:
                logger.warning(f"âš ï¸ [{server_name.upper()}] ì—°ê²° ì‹¤íŒ¨: {e}")
        
        if not all_openai_tools:
            raise HTTPException(status_code=503, detail="MCP ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.info(f"ğŸ”§ ì´ {len(all_openai_tools)}ê°œ ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥: {[t['function']['name'] for t in all_openai_tools]}")

        # (2) ì—ì´ì „íŠ¸ ì‹¤í–‰ ë¡œì§
        # ë©”ì‹œì§€ ì´ˆê¸°í™”
        messages = [
            {"role": "system", "content": SYSTEM_INSTRUCTION},
            {"role": "user", "content": request.query}
        ]

        # OpenAI API í˜¸ì¶œ (ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥)
        response = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            tools=all_openai_tools if all_openai_tools else None,
            tool_choice="auto" if all_openai_tools else None,
            temperature=0
        )

        assistant_message = response.choices[0].message

        # ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš° ì²˜ë¦¬
        while assistant_message.tool_calls:
            logger.info(f"ğŸ”§ ë„êµ¬ í˜¸ì¶œ ê°ì§€: {len(assistant_message.tool_calls)}ê°œ")
            
            # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€
            messages.append(assistant_message)

            # ê° ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
            for tool_call in assistant_message.tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)
                
                logger.info(f"   ğŸ“Œ ë„êµ¬ ì‹¤í–‰: {function_name}({function_args})")
                
                # í•´ë‹¹ ë„êµ¬ê°€ ì†í•œ MCP ì„œë²„ ì°¾ê¸°
                server_url = tool_to_server.get(function_name)
                if not server_url or server_url not in mcp_clients:
                    tool_result = f"ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {function_name}"
                    logger.error(f"   âŒ {tool_result}")
                else:
                    # MCPë¥¼ í†µí•´ ë„êµ¬ ì‹¤í–‰
                    mcp_client = mcp_clients[server_url]
                    result = await mcp_client.call_tool(function_name, function_args)
                    tool_result = str(result.content[0].text) if result.content else "ê²°ê³¼ ì—†ìŒ"
                    logger.info(f"   âœ… ë„êµ¬ ê²°ê³¼: {tool_result}")
                
                # ë„êµ¬ ê²°ê³¼ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": tool_result
                })

            # ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì‹œ ì‘ë‹µ ìƒì„±
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                tools=all_openai_tools if all_openai_tools else None,
                tool_choice="auto" if all_openai_tools else None,
                temperature=0
            )
            assistant_message = response.choices[0].message

        final_response = assistant_message.content
        logger.info(f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        logger.info(f"ğŸ“Š ì‘ë‹µ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(final_response) if final_response else 0}")

        # (3) MCP í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
        for mcp_client in mcp_clients.values():
            try:
                await mcp_client.__aexit__(None, None, None)
            except:
                pass

        # (4) ê²°ê³¼ ë°˜í™˜
        return {"response": final_response}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸ìš©"""
    return {"status": "ok", "mcp_servers": MCP_SERVERS}

if __name__ == "__main__":
    logger.info("ğŸš€ AI Stylist API ì„œë²„ ì‹œì‘ (í¬íŠ¸: 8004)")
    logger.info(f"ğŸ“¡ MCP ì„œë²„ ëª©ë¡: {list(MCP_SERVERS.keys())}")
    uvicorn.run(app, host="0.0.0.0", port=8004)