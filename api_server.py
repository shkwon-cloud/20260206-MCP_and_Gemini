# api_server.py
import os
import logging
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from openai import AsyncOpenAI
from fastmcp import Client
import uvicorn
import json

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MCP_SERVER_URL = "http://localhost:8002/sse"  # Fashion Server ì£¼ì†Œ

# 2. FastAPI ì•± ìƒì„±
app = FastAPI(title="AI Stylist API")

# CORS ì„¤ì • (React ì—°ë™ í•„ìˆ˜)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_INSTRUCTION = """
ë‹¹ì‹ ì€ íŒ¨ì…˜ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ë°˜ë“œì‹œ ì œê³µëœ ë„êµ¬(tools)ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ê³ , ë°˜ë“œì‹œ ë„êµ¬ë¥¼ í˜¸ì¶œí•´ì„œ ì •ë³´ë¥¼ ì–»ì€ í›„ ë‹µë³€í•˜ì„¸ìš”.
"""

# 3. ìš”ì²­ ë°ì´í„° êµ¬ì¡° ì •ì˜
class ChatRequest(BaseModel):
    query: str  # ì˜ˆ: "ideabong ì˜¤ëŠ˜ ë­ ì…ì–´?"

# 4. OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì „ì—­ìœ¼ë¡œ í•œ ë²ˆë§Œ)
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# MCP ë„êµ¬ë¥¼ OpenAI í•¨ìˆ˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
def convert_mcp_tools_to_openai(mcp_tools):
    """MCP ë„êµ¬ ëª©ë¡ì„ OpenAI function calling í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    openai_tools = []
    for tool in mcp_tools:
        openai_tool = {
            "type": "function",
            "function": {
                "name": tool.name,
                "description": tool.description or "",
                "parameters": tool.inputSchema if hasattr(tool, 'inputSchema') and tool.inputSchema else {"type": "object", "properties": {}}
            }
        }
        openai_tools.append(openai_tool)
    return openai_tools

# 5. ì„œë²„ ì‹œì‘ ì‹œ ë„êµ¬ ëª©ë¡ ì¶œë ¥
@app.on_event("startup")
async def startup_event():
    logger.info("ğŸ“¡ MCP ì„œë²„ì— ì—°ê²°í•˜ì—¬ ë„êµ¬ ëª©ë¡ í™•ì¸ ì¤‘...")
    try:
        mcp_client = Client(MCP_SERVER_URL)
        async with mcp_client:
            tools_list = await mcp_client.list_tools()
            logger.info(f"ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ({len(tools_list)}ê°œ):")
            for tool in tools_list:
                logger.info(f"   ğŸ“Œ {tool.name}")
                logger.info(f"      ì„¤ëª…: {tool.description}")
                if hasattr(tool, 'inputSchema') and tool.inputSchema:
                    params = tool.inputSchema.get('properties', {})
                    if params:
                        logger.info(f"      íŒŒë¼ë¯¸í„°: {list(params.keys())}")
    except Exception as e:
        logger.warning(f"âš ï¸ MCP ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")

# 6. API ì—”ë“œí¬ì¸íŠ¸ ìƒì„±
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    """
    Reactì—ì„œ ì§ˆë¬¸ì„ ë°›ì•„ OpenAI Agentë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    logger.info(f"ğŸ“¨ ìš”ì²­ ë°›ìŒ: {request.query}")

    try:
        # (1) MCP í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
        mcp_client = Client(MCP_SERVER_URL)

        # (2) ì—ì´ì „íŠ¸ ì‹¤í–‰ ë¡œì§
        async with mcp_client:
            logger.info("âœ… MCP ì„œë²„ ì—°ê²° ì„±ê³µ")

            # MCP ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            mcp_tools = await mcp_client.list_tools()
            openai_tools = convert_mcp_tools_to_openai(mcp_tools)
            logger.info(f"ğŸ”§ ë³€í™˜ëœ OpenAI ë„êµ¬: {[t['function']['name'] for t in openai_tools]}")

            # ë©”ì‹œì§€ ì´ˆê¸°í™”
            messages = [
                {"role": "system", "content": SYSTEM_INSTRUCTION},
                {"role": "user", "content": request.query}
            ]

            # OpenAI API í˜¸ì¶œ (ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥)
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                tools=openai_tools if openai_tools else None,
                tool_choice="auto" if openai_tools else None,
                temperature=0
            )

            assistant_message = response.choices[0].message

            # ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš° ì²˜ë¦¬
            while assistant_message.tool_calls:
                logger.info(f"ğŸ”§ ë„êµ¬ í˜¸ì¶œ ê°ì§€: {len(assistant_message.tool_calls)}ê°œ")
                
                # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€
                messages.append(assistant_message)

                # ê° ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
                for tool_call in assistant_message.tool_calls:
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)
                    
                    logger.info(f"   ğŸ“Œ ë„êµ¬ ì‹¤í–‰: {function_name}({function_args})")
                    
                    # MCPë¥¼ í†µí•´ ë„êµ¬ ì‹¤í–‰
                    result = await mcp_client.call_tool(function_name, function_args)
                    tool_result = str(result.content[0].text) if result.content else "ê²°ê³¼ ì—†ìŒ"
                    
                    logger.info(f"   âœ… ë„êµ¬ ê²°ê³¼: {tool_result}")
                    
                    # ë„êµ¬ ê²°ê³¼ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": tool_result
                    })

                # ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì‹œ ì‘ë‹µ ìƒì„±
                response = await openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=messages,
                    tools=openai_tools if openai_tools else None,
                    tool_choice="auto" if openai_tools else None,
                    temperature=0
                )
                assistant_message = response.choices[0].message

            final_response = assistant_message.content
            logger.info(f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ")
            logger.info(f"ğŸ“Š ì‘ë‹µ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(final_response) if final_response else 0}")

            # (3) ê²°ê³¼ ë°˜í™˜
            return {"response": final_response}

    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸ìš©"""
    return {"status": "ok", "mcp_server": MCP_SERVER_URL}

if __name__ == "__main__":
    logger.info("ğŸš€ AI Stylist API ì„œë²„ ì‹œì‘ (í¬íŠ¸: 8004)")
    uvicorn.run(app, host="0.0.0.0", port=8004)